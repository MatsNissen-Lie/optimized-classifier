{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_error_rate(y_pred, y, test_type=\"\"):\n",
    "    num_errors = np.sum(y_pred != y)\n",
    "    n = y_pred.shape[0]\n",
    "    error_rate = (num_errors / n) * 100\n",
    "    print(f\"{test_type} error rate: {error_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Oct 25 07:34:38 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Oct 25 07:34:38 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.11.4210). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/classifier_dataset.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CIO/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/classifier_dataset.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadmat\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/classifier_dataset.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract variables\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_train \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraindataset\u001b[39m\u001b[38;5;124m'\u001b[39m]     \u001b[38;5;66;03m# Training data (400 x 784)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CIO/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CIO/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CIO/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/CIO/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/classifier_dataset.mat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the dataset\n",
    "data = loadmat('data/classifier_dataset.mat')\n",
    "\n",
    "# Extract variables\n",
    "X_train = data['traindataset']     # Training data (400 x 784)\n",
    "y_train = data['trainlabels'].flatten()  # Training labels (400,)\n",
    "N_train, D = X_train.shape\n",
    "\n",
    "X_test = data['testdataset']       # Test data (1600 x 784)\n",
    "y_test = data['testlabels'].flatten()    # Test labels (1600,)\n",
    "N_test = X_test.shape[0]\n",
    "\n",
    "# Regularization parameter\n",
    "rho = 0.1\n",
    "# rho = 0.5\n",
    "\n",
    "# Define variables for optimization\n",
    "w0 = cp.Variable()  # Scalar bias term\n",
    "w = cp.Variable(D)  # Weight vector of size D\n",
    "\n",
    "# Define the hinge loss function\n",
    "u = cp.multiply(y_train, w0 + X_train @ w)  # y_n * (w0 + x_n.T @ w)\n",
    "loss = (1 / N_train) * cp.sum(cp.pos(1 - u))  # Hinge loss\n",
    "reg = rho * cp.norm(w, 2)**2  # Regularization term\n",
    "objective = cp.Minimize(loss + reg)\n",
    "\n",
    "# Solve the optimization problem\n",
    "problem = cp.Problem(objective)\n",
    "problem.solve()\n",
    "\n",
    "# Extract optimal parameters\n",
    "w0_value = w0.value\n",
    "w_value = w.value\n",
    "\n",
    "# Compute predictions and error rate on training data\n",
    "scores_train = w0_value + X_train @ w_value  # Scores for training data\n",
    "y_pred_train = np.sign(scores_train)         # Predicted labels for training data\n",
    "\n",
    "# Handle the case when score is zero (assign label 1 when score is zero)\n",
    "y_pred_train[scores_train == 0] = 1\n",
    "\n",
    "\n",
    "calculate_error_rate(y_pred_train, y_train, \"Training\")\n",
    "\n",
    "scores_test = w0_value + X_test @ w_value    # Scores for test data\n",
    "y_pred_test = np.sign(scores_test)           # Predicted labels for test data\n",
    "\n",
    "# Handle the case when score is zero (assign label 1 when score is zero)\n",
    "y_pred_test[scores_test == 0] = 1\n",
    "\n",
    "\n",
    "calculate_error_rate(y_pred_test, y_test, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGxElEQVR4nO3coY4UWRSA4a5NG4JCjiIBQSYhPAGChIQEDxbLG6CxvAsWBx4MGRJAEkCMhAQEjlqz+6vNpu8sU130fp+uk3vN9J8j5k7zPM8bANhsNn/s+wIArIcoABBRACCiAEBEAYCIAgARBQAiCgBku+uH0zSd5z0AOGe7/K+yTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAZLvvC8BavHnzZnjm5cuXwzMPHz4cnoGl2BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAECmeZ7nnT6cpvO+C+zVycnJ8MyNGzeGZ+7cuTM8s9lsNs+fPz/THPxtl597mwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAMh23xeA39mPHz+GZzxsx5rZFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQDyIB//B06dP930F+KVsCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQLySCn+Zpml45ubNm+dwE9gfmwIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgH8ThIDx48GJ45Pj4entlu/QlxWGwKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgXvPiIH369Gl45iyP2z158mR4BtbMpgBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAOJBPA7So0ePFjnn6tWri5wDS7EpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8UoqB+n9+/fDM3fv3h2eOTo6Gp6BNbMpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAeBCPg3Tp0qVFzvnw4cMi58BSbAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAexOMgHR8fL3LOs2fPFjkHlmJTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8SAeB+nKlSuLnPP169dFzoGl2BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEA8iMdBmqZpeObbt2/DM+/evRuegTWzKQAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPFKKqt37dq14ZmLFy8Oz3z//n145vT0dHgG1symAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA4kE8Vu/y5cvDM2d5EO/Vq1fDM3BobAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAexGP1bt++vcg5r1+/XuQcWDObAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiAfxWL379+8vcs7p6enwzPXr14dn3r59OzwDS7EpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGATPM8zzt9OE3nfRf4Rz9//lzknM+fPw/P3Lp1a3jm48ePwzPwK+zyc29TACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAst33Bfj/uHDhwr6v8K8eP348POPFUw6NTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAMSDeCzm3r17Z5qbpml45suXL8MzL168GJ6BQ2NTACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAmeZ5nnf68AyPkgGwHrv83NsUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEC2u344z/N53gOAFbApABBRACCiAEBEAYCIAgARBQAiCgBEFACIKACQPwHyuHVZNU8IWwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_im(x):\n",
    "    # Reshape the flattened image back to 28x28\n",
    "    image = x.reshape(28, 28).T  # Transpose to match the original orientation\n",
    "    \n",
    "    # Rescale the image data to [0, 255]\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    image_rescaled = (image - min_val) / (max_val - min_val) * 255\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image_rescaled, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# Example usage\n",
    "sample_index = 1  # Change this index to view different images\n",
    "show_im(X_test[sample_index])\n",
    "print(f'Label: {y_test[sample_index]}')  # -1 for digit 0, 1 for digit 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Test error rate: 43.56%\n"
     ]
    }
   ],
   "source": [
    "## Adversarial Attack Implementation\n",
    "\n",
    "def compute_perturbation(X, y, w, P):\n",
    "    \"\"\"\n",
    "    Computes the optimal perturbation for a set of inputs.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input data matrix (N x D)\n",
    "    - y: True labels vector (N,)\n",
    "    - w: Weight vector of the classifier (D,)\n",
    "    - P: Perturbation bound (scalar)\n",
    "\n",
    "    Returns:\n",
    "    - X_adv: Adversarially perturbed data matrix (N x D)\n",
    "    \"\"\"\n",
    "    # Compute sign(y * w) for each feature\n",
    "    sign_yw = np.sign(y[:, np.newaxis] * w[np.newaxis, :])  # Shape: (N, D)\n",
    "    \n",
    "    # Compute perturbation\n",
    "    perturbation = P * sign_yw  # Shape: (N, D)\n",
    "    \n",
    "    # Apply perturbation: x̃ = x - P * sign(yw)\n",
    "    X_adv = X - perturbation\n",
    "    \n",
    "    # Ensure perturbations are within [-P, P]\n",
    "    X_adv = np.clip(X_adv, X - P, X + P)\n",
    "    \n",
    "    return X_adv\n",
    "\n",
    "# Define perturbation magnitude P\n",
    "P = 0.18  # Adjust as needed\n",
    "\n",
    "# Generate adversarial examples for the test set\n",
    "X_test_adv = compute_perturbation(X_test, y_test, w_value, P)\n",
    "\n",
    "# Compute predictions on adversarial test data\n",
    "scores_test_adv = w0_value + X_test_adv @ w_value\n",
    "y_pred_test_adv = np.sign(scores_test_adv)\n",
    "y_pred_test_adv[scores_test_adv == 0] = 1\n",
    "\n",
    "# Calculate error rate on adversarial test data\n",
    "calculate_error_rate(y_pred_test_adv, y_test, \"Adversarial Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error rate: 0.75%\n",
      "Test error rate: 0.44%\n",
      "Adversarial Test error rate: 2.19%\n"
     ]
    }
   ],
   "source": [
    "# Regularization parameter\n",
    "rho = 0.1\n",
    "\n",
    "# Perturbation bound\n",
    "P = 0.18  # You can adjust this value as needed\n",
    "\n",
    "# Define variables for optimization\n",
    "w0 = cp.Variable()      # Scalar bias term\n",
    "w = cp.Variable(D)      # Weight vector of size D\n",
    "\n",
    "# Compute ||w||_1 once, since it's the same for all samples\n",
    "w_l1 = cp.norm1(w)\n",
    "\n",
    "\n",
    "# Define the adjusted hinge loss\n",
    "# For each sample: h(y_n (w0 + x_n^T w) - P ||w||_1), note that ||w*y||_1 = ||w||_1 because y = {-1, 1}\n",
    "u = cp.multiply(y_train, w0 + X_train @ w) - P * w_l1\n",
    "#  y_train * (w0 + X_train @ w) - P * w_l1  # Shape: (N_train,)\n",
    "\n",
    "# Hinge loss: max(0, 1 - u)\n",
    "loss = (1 / N_train) * cp.sum(cp.pos(1 - u))\n",
    "\n",
    "# Regularization term\n",
    "reg = rho * cp.norm(w, 2)**2  # L2 regularization\n",
    "\n",
    "# Objective function\n",
    "objective = cp.Minimize(loss + reg)\n",
    "\n",
    "# Define and solve the problem\n",
    "problem = cp.Problem(objective)\n",
    "problem.solve()\n",
    "\n",
    "# Extract optimal parameters\n",
    "w0_value = w0.value\n",
    "w_value = w.value\n",
    "\n",
    "# Compute predictions on training data\n",
    "scores_train = w0_value + X_train @ w_value  # Scores for training data\n",
    "y_pred_train = np.sign(scores_train)         # Predicted labels for training data\n",
    "\n",
    "# Handle the case when score is zero (assign label 1 when score is zero)\n",
    "y_pred_train[scores_train == 0] = 1\n",
    "\n",
    "# Calculate error rate on training data\n",
    "calculate_error_rate(y_pred_train, y_train, \"Training\")\n",
    "\n",
    "# Compute predictions on test data\n",
    "scores_test = w0_value + X_test @ w_value    # Scores for test data\n",
    "y_pred_test = np.sign(scores_test)           # Predicted labels for test data\n",
    "\n",
    "# Handle the case when score is zero (assign label 1 when score is zero)\n",
    "y_pred_test[scores_test == 0] = 1\n",
    "\n",
    "# Calculate error rate on test data\n",
    "calculate_error_rate(y_pred_test, y_test, \"Test\")\n",
    "\n",
    "# Generate adversarial examples for the test set\n",
    "X_test_adv = compute_perturbation(X_test, y_test, w_value, P)\n",
    "\n",
    "# Compute predictions on adversarial test data\n",
    "scores_test_adv = w0_value + X_test_adv @ w_value\n",
    "y_pred_test_adv = np.sign(scores_test_adv)\n",
    "\n",
    "# Handle the case when score is zero (assign label 1 when score is zero)\n",
    "y_pred_test_adv[scores_test_adv == 0] = 1\n",
    "\n",
    "# Calculate error rate on adversarial test data\n",
    "calculate_error_rate(y_pred_test_adv, y_test, \"Adversarial Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
